{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TELMA - Toolkit Evaluator for Language Model Agents\n",
    "\n",
    "TELMA is a toolkit evaluator for language model agents or assistants. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "AI assistants or agents can be built by leveraging an agentic language model behavior. Agentic behavior is the ability to use external tools to solve tasks. For this, a language model is prompted with a set of tool definitions and instructions on how to use these tools to complete a certain task.\n",
    "\n",
    "> ***The ability of the language model to utilize these tools efficiently depends not only on the tool definitions but also on what tools are used together in a language model prompt. This project aims at evaluating and comparing different toolkits i.e. combinations of such tool definitions.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n",
    "\n",
    "TELMA provides interfaces to define language model agent tools, assemble them as toolkits, and run evaluations on these toolkits based on any defined heuristic. TELMA provides some evaluation heuristics out of the box that can be used to score and compare toolkits or extended to build custom evaluators. So the main usage steps are\n",
    "\n",
    "- Defines language model agent tools\n",
    "- Define toolkits as a combination of tools\n",
    "- Evaluate Individual toolkits on a heuristic\n",
    "- Compare toolkits to choose the best fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Tools can be defined in TELMA in multiple ways. Many frameworks/projects help build language model-based agents/ assistants and host a set of tools like Langchain, Huggingface, etc. TELMA aims to integrate with most such projects to define tools and compare toolkits.\n",
    "- Native definition (see schema definition for details)\n",
    "- From Langchain Hub tools\n",
    "- From Open AI functions\n",
    "- From Huggingface Hub Tools\n",
    "- From LlamaIndex Module Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'description': {'title': 'Description', 'type': 'string'},\n",
      "                'name': {'title': 'Name', 'type': 'string'},\n",
      "                'signature_schema': {'title': 'Signature Schema',\n",
      "                                     'type': 'object'}},\n",
      " 'required': ['name', 'description', 'signature_schema'],\n",
      " 'title': 'Tool',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "from telma import Tool\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(Tool.model_json_schema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Tool Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import Tool\n",
    "\n",
    "tool0 = Tool(\n",
    "    name=\"example tool\",\n",
    "    description=\"example tool description\",\n",
    "    signature_schema={\"type\": \"string\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define some tools from Langchain Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U duckduckgo-search\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "tool1 = DuckDuckGoSearchRun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BraveSearch\n",
    "\n",
    "tool2 = BraveSearch.from_api_key(api_key=\"xxx\", search_kwargs={\"count\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import Tool\n",
    "\n",
    "tool1 = Tool.from_langchain_tool(tool1)\n",
    "tool2 = Tool.from_langchain_tool(tool2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open AI Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define some tools from Open AI function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import FunctionDefinition\n",
    "\n",
    "tool3_params = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"to\": {\"type\": \"string\"},\n",
    "        \"body\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"additionalProperties\": \"false\",\n",
    "}\n",
    "tool3 = FunctionDefinition(\n",
    "    name=\"send_email\", parameters=tool3_params, description=\"Send an email\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types import FunctionDefinition\n",
    "\n",
    "tool4_params = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"location\": {\"type\": \"string\"},\n",
    "        \"unit\": {\"enum\": [\"celsius\", \"fahrenheit\", \"kelvin\"]},\n",
    "    },\n",
    "    \"additionalProperties\": \"false\",\n",
    "}\n",
    "\n",
    "\n",
    "tool4 = FunctionDefinition(\n",
    "    name=\"get_current_weather\",\n",
    "    parameters=tool4_params,\n",
    "    description=\"Find out about weather\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import Tool\n",
    "\n",
    "tool3 = Tool.from_openai_function(tool3)\n",
    "tool4 = Tool.from_openai_function(tool4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Hub Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define some tools from Huggingface Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers accelerate\n",
    "from transformers import load_tool\n",
    "\n",
    "tool5 = load_tool(\"text-to-speech\")\n",
    "tool6 = load_tool(\"huggingface-tools/text-to-image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import Tool\n",
    "\n",
    "tool5 = Tool.from_huggingfaceHub(tool5)\n",
    "tool6 = Tool.from_huggingfaceHub(tool6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's define some tools from the Llama Index modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "\n",
    "tool7 = QueryEngineTool(\n",
    "    query_engine=None,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"lyft_10k\",\n",
    "        description=(\n",
    "            \"Provides information about Lyft financials for year 2021. \"\n",
    "            \"Use a detailed plain text question as input to the tool.\"\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import Tool\n",
    "\n",
    "tool7 = Tool.from_llamaIndex(tool7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toolkit Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have defined a set of tools, a toolkit can be created including as many tools as follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import ToolKit\n",
    "\n",
    "tools = [tool0, tool1, tool2, tool3, tool4, tool5, tool6, tool7]\n",
    "toolkit = ToolKit(tools=tools)\n",
    "\n",
    "# toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Two Toolkits for Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example let's define two different toolkits, `Toolkit 1` with two similar search tools and `Toolkit 2` with three varied tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import ToolKit\n",
    "\n",
    "toolkit1 = ToolKit(tools=[tool1, tool2])\n",
    "toolkit2 = ToolKit(tools=[tool2, tool3, tool4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logically a language model should have difficulty choosing between tools in Toolkit 1 compared to Toolkit 2 due to the similarity of tools available and hence would be less efficient in choosing the right tool for a job. Now let's evaluate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toolkit Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define/Design Evaluation Heuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, we utilize the out-of-the-box semantic similarity evaluator to score a toolkit. The idea here is that the variety in tool definitions makes the job of the language model easier to choose between the tools for different purposes.\n",
    "\n",
    "The `Evaluator` class in TELMA can be extended to create custom evaluation heuristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from telma import SemanticDissimilarityEvaluator\n",
    "\n",
    "evaluator = SemanticDissimilarityEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and compare toolkits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the evalaution score based on our defined heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = toolkit1.evaluate(evaluator=evaluator)\n",
    "score2 = toolkit2.evaluate(evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toolkit 2 is better that Toolkit 1!\n"
     ]
    }
   ],
   "source": [
    "if score1 > score2:\n",
    "    print(\"Toolkit 1 is better that Toolkit 2!\")\n",
    "else:\n",
    "    print(\"Toolkit 2 is better that Toolkit 1!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Langchain Hub Tools](https://python.langchain.com/docs/modules/agents/tools/custom_tools)\n",
    "- [Open AI functions](https://platform.openai.com/docs/guides/function-calling)\n",
    "- [Huggingface Hub Tools](https://huggingface.co/docs/transformers/custom_tools)\n",
    "- [LlamaIndex Module Tools](https://docs.llamaindex.ai/en/stable/optimizing/agentic_strategies/agentic_strategies.html)\n",
    "- Tool Schema Definition - [JSON Schema](https://json-schema.org/understanding-json-schema/)\n",
    "- Tool Comparison - [Semantic Textual Similarity](https://www.sbert.net/docs/usage/semantic_textual_similarity.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
